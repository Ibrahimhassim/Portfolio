# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hDJlmkaPHZdDzRTn0GH4tjDfvymfvq7o
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Load the IMDB 50K dataset
df = pd.read_csv('/content/IMDB_Dataset.csv')

# Convert the target variable 'sentiment' to binary (1 for positive, 0 for negative)
df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)

# Split into features (X) and target (y)
X = df['review']
y = df['sentiment']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Use TF-IDF to vectorize the text data
tfidf = TfidfVectorizer(max_features=5000)  # Limiting to 5000 features for efficiency
X_train_tfidf = tfidf.fit_transform(X_train).toarray()
X_test_tfidf = tfidf.transform(X_test).toarray()

# Sigmoid function
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# Compute cost without regularization and class weights (for debugging)
def compute_cost(X, y, weights, reg_param=0.0):  # Set reg_param=0.0 to remove regularization temporarily
    m = len(y)
    z = np.dot(X, weights)
    h = sigmoid(z)
    eps = 1e-15  # for numerical stability
    cost = (-1/m) * np.sum(y * np.log(h + eps) + (1 - y) * np.log(1 - h + eps))
    return cost  # No regularization

# Gradient descent without class weighting (for debugging)
def gradient_descent(X, y, weights, learning_rate, iterations, reg_param=0.0):  # Set reg_param=0.0
    m = len(y)
    cost_history = []

    for i in range(iterations):
        z = np.dot(X, weights)
        h = sigmoid(z)
        gradient = np.dot(X.T, (h - y)) / m
        weights -= learning_rate * gradient
        cost = compute_cost(X, y, weights, reg_param)
        cost_history.append(cost)

        # No early stopping for now
        # if abs(prev_cost - cost) < tolerance:
        #     print(f'Early stopping at iteration {i}')
        #     break

        # Display cost every 100 iterations
        if i % 100 == 0:
            print(f'Cost after iteration {i}: {cost:.4f}')

    return weights, cost_history

# Adding intercept term to the features
X_train_tfidf = np.insert(X_train_tfidf, 0, 1, axis=1)
X_test_tfidf = np.insert(X_test_tfidf, 0, 1, axis=1)

# Initialize weights
weights = np.zeros(X_train_tfidf.shape[1])

# Define learning rate, iterations
learning_rate = 0.01  # Slightly increased learning rate to allow faster learning
iterations = 1500      # Full iterations without early stopping

# Train the model using gradient descent without regularization or class weights
weights, cost_history = gradient_descent(X_train_tfidf, y_train.values, weights, learning_rate, iterations, reg_param=0.0)

# Plot the cost function to ensure convergence
plt.plot(range(len(cost_history)), cost_history)
plt.title('Cost Function Convergence')
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.show()

# Predict function to make predictions
def predict(X, weights):
    z = np.dot(X, weights)
    return sigmoid(z) >= 0.5

# Make predictions on the test set
y_pred = predict(X_test_tfidf, weights)

# Evaluate the model
def evaluate(y_true, y_pred):
    accuracy = np.mean(y_true == y_pred)
    precision = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1)
    recall = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_true == 1)
    f1 = 2 * (precision * recall) / (precision + recall)

    print(f'Accuracy: {accuracy:.4f}')
    print(f'Precision: {precision:.4f}')
    print(f'Recall: {recall:.4f}')
    print(f'F1 Score: {f1:.4f}')

# Convert predictions to binary values (0 or 1)
y_pred_binary = y_pred.astype(int)

# Evaluate the predictions
evaluate(y_test.values, y_pred_binary)

# Plot confusion matrix to visualize performance
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5,5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.show()

# Plot the confusion matrix
plot_confusion_matrix(y_test.values, y_pred_binary)